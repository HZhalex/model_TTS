{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083cf5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/HZhalex/F5-TTS-Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be86d21",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"ckpts/F5-TTS-Vietnamese\", exist_ok=True)\n",
    "!wget -O ckpts/F5-TTS-Vietnamese/model_500000.pt https://huggingface.co/hynt/F5-TTS-Vietnamese-ViVoice/resolve/main/model_last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ca10e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9f25e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd F5-TTS-Vietnamese\n",
    "\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82330bf4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b775df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from vocos import Vocos\n",
    "from f5_tts.model import DiT, CFM\n",
    "from f5_tts.model.utils import get_tokenizer, convert_char_to_pinyin\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/content/ckpts/F5-TTS-Vietnamese/model_500000.pt\"\n",
    "VOCAB_PATH = \"/content/F5-TTS-Vietnamese/vocab.txt\"\n",
    "REF_AUDIO_PATH = \"/content/Bình (nam miền Bắc).wav\"\n",
    "REF_TEXT = \"Anh chỉ muốn được nhìn nhận như là một huấn luyện viên.\"\n",
    "GEN_TEXT = \"Xin chào, đây là văn bản tôi muốn chuyển thành giọng nói\"\n",
    "OUTPUT_PATH = \"output.wav\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "vocab_char_map, vocab_size = get_tokenizer(VOCAB_PATH, tokenizer=\"custom\")\n",
    "model = CFM(\n",
    "    transformer=DiT(\n",
    "        dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, text_mask_padding=False,\n",
    "        text_num_embeds=vocab_size, mel_dim=100, conv_layers=4, pe_attn_head=1\n",
    "    ),\n",
    "    mel_spec_kwargs=dict(\n",
    "        n_fft=1024, hop_length=256, win_length=1024, \n",
    "        n_mel_channels=100, target_sample_rate=24000, mel_spec_type=\"vocos\"\n",
    "    ),\n",
    "    odeint_kwargs=dict(method=\"euler\"),\n",
    "    vocab_char_map=vocab_char_map,\n",
    ").to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "if \"ema_model_state_dict\" in checkpoint:\n",
    "    state_dict = {k.replace(\"ema_model.\", \"\"): v for k, v in checkpoint[\"ema_model_state_dict\"].items() \n",
    "                  if k not in [\"initted\", \"step\"]}\n",
    "elif \"model_state_dict\" in checkpoint:\n",
    "    state_dict = checkpoint[\"model_state_dict\"]\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "vocoder = Vocos.from_pretrained(\"charactr/vocos-mel-24khz\").to(DEVICE)\n",
    "\n",
    "\n",
    "audio, sr = torchaudio.load(REF_AUDIO_PATH)\n",
    "if audio.shape[0] > 1:\n",
    "    audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "rms = torch.sqrt(torch.mean(torch.square(audio)))\n",
    "if rms < 0.1:\n",
    "    audio = audio * 0.1 / rms\n",
    "if sr != 24000:\n",
    "    audio = torchaudio.transforms.Resample(sr, 24000)(audio)\n",
    "audio = audio.to(DEVICE)\n",
    "\n",
    "\n",
    "text_list = [REF_TEXT + \" \" + GEN_TEXT]\n",
    "final_text = convert_char_to_pinyin(text_list)\n",
    "ref_len = audio.shape[-1] // 256\n",
    "ref_text_len = len(REF_TEXT.encode(\"utf-8\"))\n",
    "gen_text_len = len(GEN_TEXT.encode(\"utf-8\"))\n",
    "duration = ref_len + int(ref_len / ref_text_len * gen_text_len)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generated, _ = model.sample(\n",
    "        cond=audio, \n",
    "        text=final_text, \n",
    "        duration=duration, \n",
    "        steps=32, \n",
    "        cfg_strength=2.0, \n",
    "        sway_sampling_coef=-1.0\n",
    "    )\n",
    "    generated = generated[:, ref_len:, :]\n",
    "    gen_mel_spec = generated.permute(0, 2, 1)\n",
    "    wave = vocoder.decode(gen_mel_spec).cpu()\n",
    "    if rms < 0.1:\n",
    "        wave = wave * rms / 0.1\n",
    "\n",
    "\n",
    "sf.write(OUTPUT_PATH, wave.squeeze().numpy(), 24000)\n",
    "print(f\"saved: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dce20d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
